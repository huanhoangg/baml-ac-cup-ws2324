{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "kg6ocH9MmZokcgXjX1X3DK",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Import and install packages\n",
    "%pip install pyfood\n",
    "%pip install imblearn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\n",
    "from pyfood.utils import Shelf\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "IJwHFWniGxglpWLT347OTu",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Set seed value\n",
    "seed = 2024\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "qkoxBoNK4w21ia0kjvR1bF",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Read and preprocess diets\n",
    "diets = pd.read_csv(\"diet.csv\")\n",
    "diets['Diet'].fillna('Missing', inplace=True)\n",
    "\n",
    "# Replace 'Missing' with the mode\n",
    "diets['Diet'] = diets['Diet'].replace('Missing', diets['Diet'].mode().iloc[0])\n",
    "\n",
    "# Define the mapping\n",
    "mapping = {'Omnivore': 0, 'Vegetarian': 1, 'Vegan': 2}\n",
    "# Map the values in the 'Omnivore' column\n",
    "diets['Diet2'] = diets['Diet'].map(mapping)\n",
    "\n",
    "# Create separate columns for diet type\n",
    "diets = pd.get_dummies(diets, columns=['Diet'], dtype='int')\n",
    "\n",
    "diets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "kxAffIbr83GlMMVnrLSmIC",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Read and preprocess reviews\n",
    "reviews = pd.read_csv(\"reviews.csv\", dtype={'AuthorId': str, 'RecipeId': int, 'Rating': float, 'Like': float, 'TestSetId': float})\n",
    "\n",
    "reviews = reviews.drop('Rating', axis=1)\n",
    "# reviews['Rating'] = reviews['Rating'].fillna(0)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "xJXOTCED3pFh9sjsPECOnl",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Read and preprocess recipes\n",
    "recipes = pd.read_csv(\"recipes.csv\")\n",
    "\n",
    "recipes['RecipeIngredientParts'] = [ingredient[5:-4].lower() if ingredient.startswith(\"c\") else ingredient[1:-1].lower() for ingredient in recipes['RecipeIngredientParts']]\n",
    "recipes['RecipeIngredientParts'] = recipes['RecipeIngredientParts'].str.replace('\\\\', \"\", regex=False)\n",
    "recipes['RecipeIngredientParts'] = recipes['RecipeIngredientParts'].str.split(r'\"\", \"\"')\n",
    "\n",
    "# Add new column: TotalTime = CookTime + PrepTime\n",
    "total_time = recipes['CookTime'] + recipes['PrepTime']\n",
    "recipes.insert(4,'TotalTime', total_time)\n",
    "\n",
    "# Collect all the ingredients and put it into a list\n",
    "all_ingredients_list = [ingredient for recipe in recipes['RecipeIngredientParts'] for ingredient in recipe if len(ingredient) != 0]\n",
    "all_ingredients_set = set(all_ingredients_list)\n",
    "\n",
    "# Create list of food that should be avoided by vegan and vegetarians\n",
    "shelf = Shelf(lang_source='en')\n",
    "\n",
    "vegetarian_avoid = []\n",
    "vegan_avoid = []\n",
    "\n",
    "for ingredient in all_ingredients_set:\n",
    "    label = shelf.process_ingredients([ingredient])\n",
    "    if label is not None:\n",
    "        if not label[\"labels\"][\"vegan\"]:\n",
    "            vegan_avoid.append(ingredient)\n",
    "        if not label[\"labels\"][\"vege\"]:\n",
    "            vegetarian_avoid.append(ingredient)\n",
    "\n",
    "# Add 2 columns to identify  whether the recipe is vegan or vegetarian\n",
    "vegan_labels = []\n",
    "vegetarian_labels = []\n",
    "\n",
    "for ingredients in recipes['RecipeIngredientParts']:\n",
    "    if set(ingredients) & set(vegetarian_avoid):\n",
    "        vegetarian_labels.append(0)\n",
    "    else:\n",
    "        vegetarian_labels.append(1)\n",
    "    if set(ingredients) & set(vegan_avoid):\n",
    "        vegan_labels.append(0)\n",
    "    else:\n",
    "        vegan_labels.append(1)\n",
    "\n",
    "recipes['IsRecipeVegan'] = vegan_labels\n",
    "recipes['IsRecipeVegetarian'] = vegetarian_labels\n",
    "\n",
    "\n",
    "recipes = recipes.drop([\"RecipeIngredientQuantities\", \"RecipeIngredientParts\", \"Name\", \"RecipeYield\", \"RecipeServings\",\n",
    "                       \"CookTime\", \"PrepTime\", \"CholesterolContent\", \"SodiumContent\", \"CarbohydrateContent\"], axis=1)\n",
    "\n",
    "recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "IxL22bdza7IcCbHDCXQLfF",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Read and preprocess requests\n",
    "requests = pd.read_csv(\"requests.csv\")\n",
    "\n",
    "# Replace negative time with 0\n",
    "requests['Time'] = requests['Time'].apply(lambda x: max(0, x))\n",
    "\n",
    "protein_mapping = {'Indifferent': 0, 'Yes': 1}\n",
    "requests['HighProtein'] = requests['HighProtein'].map(protein_mapping)\n",
    "\n",
    "sugar_mapping = {'0': 0, 'Indifferent': 1}\n",
    "requests['LowSugar'] = requests['LowSugar'].map(sugar_mapping)\n",
    "\n",
    "requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "9a50zvcRS12jwE3vWGzd6X",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Merge dataframe\n",
    "# requests x diets on AuthorId\n",
    "merged1 = pd.merge(requests, diets, on='AuthorId')\n",
    "\n",
    "# merged1 (requests x diets) x recipes of RecipeId\n",
    "merged2 = pd.merge(merged1, recipes, on=\"RecipeId\")\n",
    "\n",
    "# Diet compatibility\n",
    "compatibility = []\n",
    "isCustVegan = merged2['Diet_Vegan'].tolist()\n",
    "isCustVege = merged2['Diet_Vegetarian'].tolist()\n",
    "isRecipeVegan = merged2['IsRecipeVegan'].tolist()\n",
    "isRecipeVege = merged2['IsRecipeVegetarian'].tolist()\n",
    "\n",
    "for i in range(len(isCustVegan)):\n",
    "    if (isCustVegan[i] == 1 and isRecipeVegan[i] == 0) or (isCustVege[i] == 1 and isRecipeVege[i] == 0):\n",
    "        compatibility.append(0)\n",
    "    else:\n",
    "        compatibility.append(1)\n",
    "\n",
    "merged2['Compatibility'] = compatibility\n",
    "\n",
    "# merged2['TimeDiff'] = merged2['Time'] - merged2['TotalTime']\n",
    "# merged2['TimeDiff'] = merged2['TimeDiff'].abs() < merged2['TimeDiff'].mean()\n",
    "# merged2['TimeDiff'] = merged2['TimeDiff'].astype(int)\n",
    "\n",
    "merged2 = merged2.drop(['Time', 'TotalTime'], axis=1)\n",
    "\n",
    "# merged2 reviews x (requests x diets x recipes) on \"AuthorId\" and \"RecipeId\")\n",
    "mergedAll = pd.merge(reviews, merged2, on = [\"AuthorId\", \"RecipeId\"])\n",
    "mergedAll = mergedAll.drop([\"Diet_Omnivore\", \"Diet_Vegan\", \"IsRecipeVegan\",\"AuthorId\", \"RecipeId\", \"Diet_Vegetarian\", \"IsRecipeVegetarian\",\n",
    "                           \"SaturatedFatContent\"], axis = 1)\n",
    "\n",
    "mapping = {'Other' : 0, \n",
    "           'Lunch': 1, \n",
    "           'One dish meal': 2, \n",
    "           'Bread': 3, \n",
    "           'Breakfast': 4, \n",
    "           'Beverages': 5, \n",
    "           'Soup': 6}\n",
    "mergedAll[\"RecipeCategory\"] = mergedAll[\"RecipeCategory\"].map(mapping)\n",
    "\n",
    "mergedAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "OMAQuJmECB5HBtoAsKfLkT",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "trainData = mergedAll[mergedAll['TestSetId'].isna()]\n",
    "trainData = trainData.drop(\"TestSetId\", axis=1)\n",
    "trainData[\"Like\"] = trainData[\"Like\"].astype(\"int\")\n",
    "\n",
    "numeric_columns = trainData.select_dtypes(include=[np.number]).columns\n",
    "z_scores = zscore(trainData[numeric_columns])\n",
    "threshold = 30 #30 - 83.50\n",
    "outlier_mask = np.abs(z_scores) <= threshold\n",
    "trainData = trainData[outlier_mask.all(axis=1)]\n",
    "\n",
    "testData = mergedAll[~mergedAll['TestSetId'].isna()]\n",
    "\n",
    "X = trainData.drop(\"Like\", axis = 1)\n",
    "Y = trainData[\"Like\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "UVhDJIBZ5KEumznvQlRSUE",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Training with random forest\n",
    "rf = RandomForestClassifier(random_state=seed,\n",
    "                            n_estimators=1000,\n",
    "                            max_depth=20,\n",
    "                            min_samples_split=10,\n",
    "                            min_samples_leaf=20,\n",
    "                            class_weight='balanced',\n",
    "                            bootstrap=False,\n",
    "                            criterion='gini',\n",
    "                            n_jobs=-1)\n",
    "\n",
    "ros = RandomOverSampler(random_state=seed)\n",
    "X_resampled_train, y_resampled_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "rf.fit(X_resampled_train, y_resampled_train)\n",
    "\n",
    "# Get predicted probabilities on the validation set\n",
    "y_pred_proba = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Threshold search\n",
    "best_threshold = 0\n",
    "best_balanced_accuracy = 0\n",
    "\n",
    "for threshold in np.arange(0, 1.01, 0.001):\n",
    "    # Adjust classification threshold\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    balanced_accuracy = balanced_accuracy_score(y_val, y_pred)\n",
    "\n",
    "    if balanced_accuracy > best_balanced_accuracy:\n",
    "        best_balanced_accuracy = balanced_accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Apply the best threshold to get final predictions\n",
    "y_pred_final = (y_pred_proba > best_threshold).astype(int)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Balanced Accuracy: {:.2f}%\".format(best_balanced_accuracy * 100))\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val, y_pred_final)\n",
    "classification_rep = classification_report(y_val, y_pred_final)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "ETH14rEM7ZVHXUKTDX9gyi",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Write predictions into csv\n",
    "X = testData.sort_values(\"TestSetId\")\n",
    "X[\"TestSetId\"] = X[\"TestSetId\"].astype(\"int\")\n",
    "\n",
    "TestSetId = X[\"TestSetId\"]\n",
    "X = testData.drop([\"Like\", \"TestSetId\"], axis=1)\n",
    "\n",
    "result_y = rf.predict(X).astype(\"int\")\n",
    "\n",
    "# Get predicted probabilities on the validation set\n",
    "result_y = rf.predict_proba(X)[:, 1]\n",
    "result_y = (result_y > best_threshold).astype(int)\n",
    "\n",
    "output = pd.DataFrame()\n",
    "output[\"id\"] = TestSetId\n",
    "output['prediction'] = result_y\n",
    "\n",
    "output.to_csv('prediction_PinguHunters_9.csv', index=False)\n",
    "print(\"0: \",output['prediction'].value_counts()[0], \"making up \", output['prediction'].value_counts()[0]/len(output['prediction']))\n",
    "print(\"1: \",output['prediction'].value_counts()[1], \"making up \", output['prediction'].value_counts()[1]/len(output['prediction']))\n",
    "\n",
    "result_y"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [
    {
     "name": "pyfood",
     "source": "PIP",
     "version": "0.0.5"
    },
    {
     "name": "imblearn",
     "source": "PIP"
    },
    {
     "name": "k-fold-imblearn",
     "source": "PIP"
    }
   ],
   "report_row_ids": [
    "D90WjBrOyeirhoJBbb1tMk",
    "MjFtbDEHwXAhjDYSJwQ8N4",
    "EHjgyM8mRM0ISOUntsKPGn",
    "NeHM3nNFJQEjnlJbypdXAA"
   ],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
